{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.io import savemat, loadmat\nfrom scipy.spatial.distance import cdist\nfrom numpy import random,matlib,linalg\nfrom PIL import Image\n#for Jupyter Notebook\n%matplotlib inline \nclass pycolor:\n    RED = '\\033[31m'\n    END = '\\033[0m'"},{"cell_type":"markdown","metadata":{},"source":"# Dataset"},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":"fMRI = loadmat('../data/fMRI_activity.mat')\nVisual_category = loadmat('../data/visual&category.mat')\nv_candidate = Visual_category['VGG19_candidate'].T\nc_candidate = Visual_category['word2vec_candidate'].T\nadd_features = loadmat('../data/additional_visual&category.mat')\nVGG19_ILSVRC = add_features['VGG19_ILSVRC'].T\nword2vec_ILSVRC = add_features['word2vec_ILSVRC'].T\nVGG19_ILSVRC_without = add_features['VGG19_ILSVRC_without'].T\nword2vec_ILSVRC_without = add_features['word2vec_ILSVRC_without'].T\ndef dataset(subject):\n    f_train = fMRI['sub0{}_train'.format(subject)].T\n    f_test = fMRI['sub0{}_test_ave'.format(subject)].T\n    if subject == 1 or subject == 2 or subject == 3:\n        v_train = Visual_category['VGG19_train'].T\n        c_train = Visual_category['word2vec_train'].T\n    else:\n        v_train = Visual_category['VGG19_train_sub0{}'.format(subject)].T\n        c_train = Visual_category['word2vec_train_sub0{}'.format(subject)].T\n    print('Voxels : {}'.format(f_train.shape[0]))\n    return f_train,v_train,c_train,f_test"},{"cell_type":"markdown","metadata":{},"source":"# Parameters"},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":"def parameter(f_train,v_train,c_train,f_test):\n    N = f_train.shape[1]\n    N_test = f_test.shape[1]\n    D = [f_train.shape[0],v_train.shape[0],c_train.shape[0]]\n    Dz = min(D[0],D[1],D[2])\n    print('Dimensions of latent variables : {}'.format(Dz))\n    return N,N_test,D,Dz"},{"cell_type":"markdown","metadata":{},"source":"# Normalize"},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":"def normalize(f_train,v_train,c_train):\n    N = np.size(f_train,1)\n    X_mean = [np.mean(f_train,axis=1),np.mean(v_train,axis=1),np.mean(c_train,axis=1)]\n    X_norm = [np.std(f_train,axis=1,ddof=1),np.std(v_train,axis=1,ddof=1),np.std(c_train,axis=1,ddof=1)]\n    X_train = [f_train-matlib.repmat(X_mean[0],N,1).T,v_train-matlib.repmat(X_mean[1],N,1).T,c_train-matlib.repmat(X_mean[2],N,1).T]\n    X = [X_train[0]/matlib.repmat(X_norm[0],N,1).T,X_train[1]/matlib.repmat(X_norm[1],N,1).T,X_train[2]/matlib.repmat(X_norm[2],N,1).T]\n    return X,X_mean,X_norm\ndef normalize_item(item,X_mean,X_norm):\n    N_item = np.size(item,1)\n    item = item-matlib.repmat(X_mean,N_item,1).T\n    item = item/matlib.repmat(X_norm,N_item,1).T\n    return item\ndef renormalize_item(item,X_mean,X_norm):\n    N_item = np.size(item,1)\n    item = item*matlib.repmat(X_norm,N_item,1).T\n    item = item+matlib.repmat(X_mean,N_item,1).T\n    return item"},{"cell_type":"markdown","metadata":{},"source":"# Hyper-parameters"},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":"subject = 3 # subject index\nmaxiter = 10 # number of updating model parameters\nthres_a_inv = 1e-1 # ARD parameter\neta = 0.5 # trade-off parameter between visual features and category features\nN_trial = 10 # trial numbers of model training and prediction (N_trial was set to 1000 in the original paper.)"},{"cell_type":"markdown","metadata":{},"source":"# Initialize"},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":"def initialize(X,N,D,Dz):   \n    # Z\n    Z = random.randn(Dz,N)\n    SigmaZ_inv = np.eye(Dz)\n    SZZ = Z@Z.T + N*SigmaZ_inv\n    SZZrep = [matlib.repmat(np.diag(SZZ),D[0],1),matlib.repmat(np.diag(SZZ),D[1],1),matlib.repmat(np.diag(SZZ),D[2],1)]\n    # alpha,gamma\n    A_inv = [np.ones((D[0],Dz)),np.ones((D[1],Dz)),np.ones((D[2],Dz))]\n    A0_inv = [np.zeros((D[0],Dz)),np.zeros((D[1],Dz)),np.zeros((D[2],Dz))]\n    gamma0 = [np.zeros((D[0],Dz)),np.zeros((D[1],Dz)),np.zeros((D[2],Dz))]\n    gamma = [1/2+gamma0[0],1/2+gamma0[1],1/2+gamma0[2]]\n    gamma_xx = [np.sum(X[0]**2)/2,np.sum(X[1]**2)/2,np.sum(X[2]**2)/2]\n    gamma_beta = [D[0]*N/2,D[1]*N/2,D[2]*N/2]\n    # beta\n    beta_inv = [1,1,1]\n    return Z,SZZrep,A_inv,A0_inv,gamma0,gamma,gamma_xx,gamma_beta,beta_inv"},{"cell_type":"markdown","metadata":{},"source":"# Update"},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":"def update(X,N,Z,SZZrep,A_inv,A0_inv,gamma0,gamma,gamma_xx,gamma_beta,beta_inv,D):\n    # initialize\n    SigmaW_inv = [0]*3\n    W = [0]*3\n    WW = [0]*3\n    beta_inv_gamma = [0]*3\n    print ('********************subject={},trial={},iteration={}'.format(subject,t,maxiter))\n    for l in range(maxiter):\n        # W-step\n        for i in range(3):\n            SigmaW_inv[i] = A_inv[i]/((1/beta_inv[i])*SZZrep[i]*A_inv[i]+1)\n            W[i] = (1/beta_inv[i])*X[i]@Z.T*SigmaW_inv[i]\n            WW[i] = np.diag(SigmaW_inv[i].sum(axis=0))+W[i].T@W[i]\n        # Z-step\n        SigmaZ = (1/beta_inv[0])*WW[0]+(1/beta_inv[1])*WW[1]+(1/beta_inv[2])*WW[2]+np.eye(Dz)\n        SigmaZ_inv = linalg.inv(SigmaZ)\n        Z =  (1/beta_inv[0])*SigmaZ_inv@W[0].T@X[0]+(1/beta_inv[1])*SigmaZ_inv@W[1].T@X[1]+(1/beta_inv[2])*SigmaZ_inv@W[2].T@X[2]\n        SZZ = Z@Z.T + N*SigmaZ_inv\n        SZZrep = [matlib.repmat(np.diag(SZZ),D[0],1),matlib.repmat(np.diag(SZZ),D[1],1),matlib.repmat(np.diag(SZZ),D[2],1)]\n        # missing obsevation\n        X[0][:,tr_num:tr_num+N_add] = W[0]@Z[:,tr_num:tr_num+N_add]\n        for i in range(3):\n            # alpha-step\n            A_inv[i] = (W[i]**2/2+SigmaW_inv[i]/2+gamma0[i]*A0_inv[i])/gamma[i]\n            # beta-step\n            beta_inv_gamma[i] = gamma_xx[i]-np.trace(W[i]@Z@X[i].T)+np.trace(SZZ@WW[i])/2\n            beta_inv[i] = beta_inv_gamma[i]/gamma_beta[i]\n        # find irrelevance parameters\n        a_inv = [A_inv[0].sum(axis=0),A_inv[1].sum(axis=0),A_inv[2].sum(axis=0)]\n        a_inv_max = [max(a_inv[0]),max(a_inv[1]),max(a_inv[2])]\n        ix_a = [a_inv[0]>a_inv_max[0]*thres_a_inv, a_inv[1]>a_inv_max[1]*thres_a_inv, a_inv[2]>a_inv_max[2]*thres_a_inv]\n        ix_z = np.logical_and(ix_a[0],ix_a[1],ix_a[2])\n    print('Effect number of dimensions (ARD) : {}'.format(np.sum(ix_z)))\n    print('Update N:',N,'tr_num:',tr_num,'N_add:',N_add)\n    return W,WW,beta_inv,Z,X"},{"cell_type":"markdown","metadata":{},"source":"# Predict"},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":"def predict(W,WW,beta_inv,f_test,D,Dz):\n    # calculate posterior z from fMRI activity\n    SigmaZnew = (1/beta_inv[0])*WW[0]+np.eye(Dz)\n    SigmaZnew_inv = linalg.inv(SigmaZnew)\n    prZ = SigmaZnew_inv@((1/beta_inv[0])*W[0].T@f_test)\n    # predictive distribution\n    v_pred = W[1]@prZ\n    v_pred_cov = W[1]@SigmaZnew_inv@W[1].T+beta_inv[1]*np.eye(D[1])\n    c_pred = W[2]@prZ\n    c_pred_cov = W[2]@SigmaZnew_inv@W[2].T+beta_inv[2]*np.eye(D[2])\n    return v_pred,c_pred"},{"cell_type":"markdown","metadata":{},"source":"# Estimate image categories"},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":"def evaluate(V_pred,C_pred):\n    # Estimate image categories from visual features\n    v_corr = (1 - cdist(V_pred.T, v_candidate.T, metric='correlation'))\n    # Estimate image categories from category features\n    c_corr = (1 - cdist(C_pred.T, c_candidate.T, metric='correlation'))\n    # Rankings of estimated image categories\n    def calc_rank(corr):\n        sort = np.sort(corr,axis=1)[:,::-1]\n        sort_ix = np.argsort(corr,axis=1)[:,::-1]\n        Rank = []\n        for i in range(N_test):\n            Rank.append(int(np.where(sort_ix[i,:]==i)[0]+1))\n        return Rank,sort,sort_ix\n    def calc_acc(corr):\n        accuracy = []\n        for i in range(np.size(corr,0)):\n            correct = 0\n            for j in range(np.size(corr,1)):\n                if corr[i,i] > corr[i,j]:\n                    correct += 1\n            accuracy.append(correct/(np.size(corr,1)-1))\n        return accuracy\n    # fusion of estimated rankings\n    corr_fusion = eta*v_corr+(1-eta)*c_corr\n    Rank_fusion,candidate_corr,candidate_ix = calc_rank(corr_fusion)\n    Acc_fusion = calc_acc(corr_fusion)\n    test_Rank_fusion = np.mean(Rank_fusion)\n    test_Acc_fusion = np.mean(Acc_fusion)\n    print('Average ranks from fusion results : {}'.format(test_Rank_fusion))\n    print('Average accuracy from fusion results : {}'.format(test_Acc_fusion))\n    return Rank_fusion,candidate_ix,test_Rank_fusion,test_Acc_fusion"},{"cell_type":"markdown","metadata":{},"source":"# Generate N-trial samples"},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Voxels : 4643\n","Dimensions of latent variables : 300\n","********************subject=3,trial=0,iteration=10\n","Effect number of dimensions (ARD) : 210\n","Update N: 2200 tr_num: 1200 N_add: 1000\n","********************subject=3,trial=1,iteration=10\n","Effect number of dimensions (ARD) : 300\n","Update N: 2200 tr_num: 1200 N_add: 1000\n","********************subject=3,trial=2,iteration=10\n","Effect number of dimensions (ARD) : 294\n","Update N: 2200 tr_num: 1200 N_add: 1000\n","********************subject=3,trial=3,iteration=10\n"]}],"source":"V_pred = C_pred = 0\nf_train,v_train,c_train,f_test = dataset(subject)\nN,N_test,D,Dz = parameter(f_train,v_train,c_train,f_test)\n# additional features\nv_add = VGG19_ILSVRC # Semi-MVBGM\nc_add = word2vec_ILSVRC # Semi-MVBGM\n#v_add = VGG19_ILSVRC_without # Semi-MVBGM-w/o\n#c_add = word2vec_ILSVRC_without # Semi-MVBGM-w/o\ntr_num = N\nN_add = np.size(v_add,axis=1)\n# normalize\nX,X_mean,X_norm = normalize(f_train,v_train,c_train)\nX_add_v,X_add_c = normalize_item(v_add,X_mean[1],X_norm[1]),normalize_item(c_add,X_mean[2],X_norm[2])\nf_prior = random.randn(D[0],N_add)\nX_semi = [np.concatenate([X[0],f_prior],1),np.concatenate([X[1],X_add_v],1),np.concatenate([X[2],X_add_c],1)]\nfor t in range(N_trial):\n    Z,SZZrep,A_inv,A0_inv,gamma0,gamma,gamma_xx,gamma_beta,beta_inv = initialize(X_semi,N+N_add,D,Dz)\n    W,WW,beta_inv,Z,X_update = update(X_semi,N+N_add,Z,SZZrep,A_inv,A0_inv,gamma0,gamma,gamma_xx,gamma_beta,beta_inv,D)\n    X_test = normalize_item(f_test,X_mean[0],X_norm[0])\n\n    v_pred,c_pred = predict(W,WW,beta_inv,X_test,D,Dz)\n    v_pred = renormalize_item(v_pred,X_mean[1],X_norm[1])\n    c_pred = renormalize_item(c_pred,X_mean[2],X_norm[2])\n\n    V_pred += v_pred\n    C_pred += c_pred\n    \n# average of N-trials\nV_pred_mean = V_pred/N_trial\nC_pred_mean = C_pred/N_trial\nprint('****************************************Estimation Result')\nRank_fusion,candidate_ix,mean_rank,mean_acc = evaluate(V_pred_mean,C_pred_mean)"},{"cell_type":"markdown","metadata":{},"source":"# Estimated image categories for each test image"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"for test_index in range(1,51):\n    # read image\n    im = Image.open('../data/test_images/test{}.JPEG'.format(test_index))\n    plt.imshow(im)\n    plt.show()\n    # read canididate\n    f = open('../data/candidate_name.txt')\n    candidate = f.readlines()\n    print('test image category : {}'.format(candidate[test_index-1]))\n    flag = 0\n    for i in range(5):\n        if i ==  Rank_fusion[test_index-1]-1:\n            print(pycolor.RED + 'Rank {} : {}'.format(i+1,candidate[candidate_ix[test_index-1,i]]) + pycolor.END)\n            flag = 1\n        else:\n            print('Rank {} : {}'.format(i+1,candidate[candidate_ix[test_index-1,i]]))\n    if flag == 0:\n        print('   *\\n   *\\n   *')\n        print(pycolor.RED + 'Rank {} : {}'.format(Rank_fusion[test_index-1],candidate[test_index-1]) + pycolor.END)"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.1"}},"nbformat":4,"nbformat_minor":2}